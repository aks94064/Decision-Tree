{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree\n",
        "##\n",
        "### Question 1: What is a Decision Tree, and how does it work in the context of classification?\n",
        "A **Decision Tree** is a supervised learning algorithm used for **classification and regression tasks**. It works by **splitting data into branches** based on feature values, forming a tree-like structure where:\n",
        "\n",
        "* **Root Node** → Represents the entire dataset.\n",
        "* **Internal Nodes** → Represent decisions or tests on features.\n",
        "* **Leaf Nodes** → Represent final outcomes or class labels.\n",
        "\n",
        "In classification, the tree divides data based on measures like **Gini Impurity** or **Entropy**, aiming to create **pure subsets** where most instances belong to a single class.\n",
        "\n",
        "##\n",
        "### Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "\n",
        "**Gini Impurity** and **Entropy** are metrics used to measure the **purity or disorder** of data at a node in a Decision Tree — they help decide the **best split**.\n",
        "\n",
        "* **Gini Impurity:**\n",
        "  Measures how often a randomly chosen sample would be **incorrectly classified** if labeled randomly based on class distribution.<br>\n",
        "$$[\n",
        "  Gini = 1 - \\sum p_i^2\n",
        "  ]$$\n",
        "  <br>Lower Gini → purer node.\n",
        "\n",
        "* **Entropy:**\n",
        "  Measures the **amount of uncertainty** or randomness in data.\n",
        " $$ [\n",
        "  Entropy = -\\sum p_i \\log_2(p_i)\n",
        "  ]$$\n",
        "  Lower entropy → higher purity.\n",
        "\n",
        "\n",
        "##\n",
        "### Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "\n",
        "**Pre-Pruning (Early Stopping):**\n",
        "Pre-pruning stops the tree from growing once a certain condition is met (e.g., maximum depth, minimum samples per split).\n",
        "\n",
        "* **Advantage:** Prevents overfitting early, making the model simpler and faster to train.\n",
        "\n",
        "**Post-Pruning (Reduced Error Pruning):**\n",
        "Post-pruning allows the tree to grow fully, then removes branches that don’t improve accuracy on validation data.\n",
        "\n",
        "* **Advantage:** Produces a more optimal and generalizable model by evaluating actual performance before trimming.\n",
        "\n",
        "##\n",
        "### Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "\n",
        "**Information Gain (IG)** measures how much **uncertainty (entropy)** in the target variable is reduced after splitting a dataset based on a feature. It helps determine **which feature provides the most useful information** for classification.\n",
        "\n",
        "$$[\n",
        "Information\\ Gain = Entropy(Parent) - \\sum \\frac{N_i}{N} \\times Entropy(Child_i)\n",
        "]$$\n",
        "\n",
        "* A **higher IG** means the feature provides a better split.\n",
        "* Decision Trees select the feature with the **maximum Information Gain** at each node, ensuring the tree becomes more **pure and efficient** in separating classes.\n",
        "\n",
        "##\n",
        "### Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "\n",
        "**Applications:**\n",
        "\n",
        "* **Finance:** Credit risk assessment and loan approval.\n",
        "* **Healthcare:** Disease diagnosis based on symptoms.\n",
        "* **Marketing:** Customer segmentation and churn prediction.\n",
        "* **Manufacturing:** Quality control and fault detection.\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Easy to **understand, visualize, and interpret**.\n",
        "* Requires little data preprocessing (no scaling or normalization).\n",
        "* Handles **numerical and categorical** data effectively.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "* Prone to **overfitting** if not pruned.\n",
        "* **Unstable** — small data changes can alter the tree structure.\n",
        "* May **favor features** with more levels (biased splits).\n",
        "\n",
        "##\n",
        "### Dataset Info:\n",
        "* Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
        "provided CSV).\n",
        "* Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV).\n",
        "##\n",
        "\n",
        "### Question 6: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier using the Gini criterion\n",
        "* Print the model’s accuracy and feature importances\n",
        "\n",
        "# --- Import Libraries ---\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load the Iris Dataset ---\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# --- Split into Train and Test Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Train Decision Tree Classifier (using Gini) ---\n",
        "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Predict and Evaluate ---\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"Decision Tree Accuracy:\", accuracy)\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, model.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "    Output: Decision Tree Accuracy: 1.0\n",
        "            Feature Importances:\n",
        "            sepal length (cm): 0.0000\n",
        "            sepal width (cm): 0.0167\n",
        "            petal length (cm): 0.9061\n",
        "            petal width (cm): 0.0772\n",
        "\n",
        "##\n",
        "### Question 7: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree\n",
        "# --- Load the Iris Dataset ---\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# --- Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Fully Grown Tree ---\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "full_pred = full_tree.predict(X_test)\n",
        "full_acc = accuracy_score(y_test, full_pred)\n",
        "\n",
        "# --- Pruned Tree (max_depth=3) ---\n",
        "pruned_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "pruned_tree.fit(X_train, y_train)\n",
        "pruned_pred = pruned_tree.predict(X_test)\n",
        "pruned_acc = accuracy_score(y_test, pruned_pred)\n",
        "\n",
        "# --- Print Comparison ---\n",
        "print(\"Accuracy of Fully Grown Tree:\", full_acc)\n",
        "print(\"Accuracy of Pruned Tree (max_depth=3):\", pruned_acc)\n",
        "\n",
        "    Output: Accuracy of Fully Grown Tree: 1.0\n",
        "            Accuracy of Pruned Tree (max_depth=3): 1.0\n",
        "##\n",
        "\n",
        "### Question 8: Write a Python program to:\n",
        "* Load the Boston Housing Dataset\n",
        "* Train a Decision Tree Regressor\n",
        "* Print the Mean Squared Error (MSE) and feature importances\n",
        "# --- Import Libraries ---\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# --- Load Boston Housing Dataset ---\n",
        "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# --- Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Train Decision Tree Regressor ---\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# --- Predict and Evaluate ---\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(X.columns, regressor.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "    \n",
        "    Output: Mean Squared Error (MSE): 10.416078431372549\n",
        "            Feature Importances:\n",
        "            CRIM: 0.0513\n",
        "            ZN: 0.0034\n",
        "            INDUS: 0.0058\n",
        "            CHAS: 0.0000\n",
        "            NOX: 0.0271\n",
        "            RM: 0.6003\n",
        "            AGE: 0.0136\n",
        "            DIS: 0.0707\n",
        "            RAD: 0.0019\n",
        "            TAX: 0.0125\n",
        "            PTRATIO: 0.0110\n",
        "            B: 0.0090\n",
        "            LSTAT: 0.1933\n",
        "##\n",
        "### Question 9: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "* Print the best parameters and the resulting model accuracy\n",
        "# --- Import Libraries ---\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Load the Iris Dataset ---\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# --- Split Data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Define Parameter Grid ---\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5, 10]\n",
        "}\n",
        "\n",
        "# --- Initialize Model and Grid Search ---\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# --- Fit the Model ---\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# --- Best Parameters and Accuracy ---\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "print(\"Test Set Accuracy:\", accuracy)\n",
        "\n",
        "    Output: Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
        "            Best Cross-Validation Accuracy: 0.9416666666666668\n",
        "            Test Set Accuracy: 1.0\n",
        "\n",
        "##\n",
        "### Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "* Handle the missing values\n",
        "* Encode the categorical features\n",
        "* Train a Decision Tree model\n",
        "* Tune its hyperparameters\n",
        "* Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "# --- Decision Tree Pipeline for Disease Prediction ---\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Simulate healthcare dataset\n",
        "# ---------------------------\n",
        "data = {\n",
        "    'Age': [25, 40, 35, np.nan, 50, 45, 60, np.nan, 30, 55],\n",
        "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female', np.nan, 'Female', 'Male', 'Female'],\n",
        "    'BloodPressure': [120, 130, np.nan, 110, 140, 125, 150, 135, np.nan, 145],\n",
        "    'Cholesterol': ['High', 'Normal', 'High', 'Normal', np.nan, 'High', 'High', 'Normal', 'High', 'Normal'],\n",
        "    'Disease': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Disease', axis=1)\n",
        "y = df['Disease']\n",
        "\n",
        "# Identify column types\n",
        "num_cols = ['Age', 'BloodPressure']\n",
        "cat_cols = ['Gender', 'Cholesterol']\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Preprocessing (handle missing values + encoding)\n",
        "# ---------------------------\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Model + Pipeline setup\n",
        "# ---------------------------\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', dt)])\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Train/Test Split\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 5: Hyperparameter Tuning\n",
        "# ---------------------------\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [2, 3, 4, 5, None],\n",
        "    'classifier__min_samples_split': [2, 4, 6],\n",
        "    'classifier__criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 6: Evaluation\n",
        "# ---------------------------\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"\\nModel Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ---------------------------\n",
        "# Step 7: Business Value Summary\n",
        "# ---------------------------\n",
        "print(\"\"\"\n",
        "✅ BUSINESS VALUE:\n",
        "- Enables early detection of diseases through data-driven insights.\n",
        "- Helps allocate medical resources efficiently.\n",
        "- Improves diagnostic accuracy and supports personalized treatment plans.\n",
        "- Provides healthcare professionals with interpretable, rule-based decisions.\n",
        "\"\"\")\n",
        "\n",
        "    Output: Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 2, 'classifier__min_samples_split': 2}\n",
        "\n",
        "Model Accuracy: 0.6666666666666666\n",
        "\n",
        "Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.50      0.67         2\n",
        "           1       0.50      1.00      0.67         1\n",
        "\n",
        "    accuracy                           0.67         3\n",
        "    macro avg       0.75      0.75      0.67         3\n",
        "    weighted avg    0.83      0.67      0.67         3\n",
        "\n",
        "Confusion Matrix:\n",
        " [[1 1]\n",
        " [0 1]]\n",
        "\n",
        "✅ BUSINESS VALUE:\n",
        "- Enables early detection of diseases through data-driven insights.\n",
        "- Helps allocate medical resources efficiently.\n",
        "- Improves diagnostic accuracy and supports personalized treatment plans.\n",
        "- Provides healthcare professionals with interpretable, rule-based decisions.\n"
      ],
      "metadata": {
        "id": "1DiryKfr9fBH"
      }
    }
  ]
}